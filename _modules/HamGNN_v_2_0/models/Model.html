

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HamGNN_v_2_0.models.Model &mdash; HamGNN 2.0 文档</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=8ba3eb92"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/translations.js?v=beaddf03"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            HamGNN
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">API 文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../source/main_entry.html">主程序入口</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/model_structure.html">模型顶层结构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/gnn_core.html">GNN 核心层</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/model_components.html">模型通用组件</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/data_processing.html">数据处理与输入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/utilities.html">通用工具函数</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">HamGNN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">模块代码</a></li>
      <li class="breadcrumb-item active">HamGNN_v_2_0.models.Model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>HamGNN_v_2_0.models.Model 源代码</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">/*</span>
<span class="sd"> * @Author: Yang Zhong </span>
<span class="sd"> * @Date: 2021-10-09 13:46:53 </span>
<span class="sd"> * @Last Modified by: Yang Zhong</span>
<span class="sd"> * @Last Modified time: 2021-10-29 21:09:02</span>
<span class="sd"> */</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">&quot;&quot;&quot;定义了核心的 PyTorch Lightning 模型封装。</span>

<span class="sd">该文件中的 `Model` 类是一个 `pytorch_lightning.LightningModule`，它将图表示网络 (representation) </span>
<span class="sd">和输出网络 (output) 组合在一起，并实现了标准的训练、验证和测试流程。它负责处理优化器配置、</span>
<span class="sd">损失计算、指标记录以及在 TensorBoard 中进行可视化。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">opt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">scatter_plot</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>


<div class="viewcode-block" id="Model">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    核心的 PyTorch Lightning 模型，用于封装和训练 GNN。</span>

<span class="sd">    这个类集成了表示网络和输出网络，并定义了完整的训练、验证和测试循环。</span>
<span class="sd">    它通过配置文件接收损失函数、评估指标和优化器参数，实现了高度的灵活性和可配置性。</span>

<span class="sd">    Attributes:</span>
<span class="sd">        representation (nn.Module): 图表示网络，用于从输入图数据中提取特征。</span>
<span class="sd">        output_module (nn.Module): 输出网络，用于从表示网络提取的特征中预测目标属性。</span>
<span class="sd">        losses (List[Dict]): 一个字典列表，定义了用于训练的损失函数。</span>
<span class="sd">        metrics (List[Dict]): 一个字典列表，定义了用于验证和测试的评估指标。</span>
<span class="sd">        post_processing (callable, optional): 一个可选的后处理函数，用于在测试阶段计算需要梯度信息的物理量。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">representation</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">output</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">losses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
            <span class="n">validation_metrics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
            <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
            <span class="n">lr_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="n">lr_patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
            <span class="n">lr_monitor</span><span class="o">=</span><span class="s2">&quot;training/total_loss&quot;</span><span class="p">,</span>
            <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
            <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span>
            <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
            <span class="n">amsgrad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">max_points_to_scatter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span>
            <span class="n">post_processing</span><span class="p">:</span> <span class="nb">callable</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        初始化 Model 类。</span>

<span class="sd">        Args:</span>
<span class="sd">            representation (nn.Module): 图表示网络实例 (例如, HamGNNConvE3)。</span>
<span class="sd">            output (nn.Module): 输出网络实例 (例如, HamGNNPlusPlusOut)。</span>
<span class="sd">            losses (List[Dict]): 损失函数配置列表。每个字典应包含 &#39;metric&#39;, &#39;prediction&#39;, &#39;target&#39;, &#39;loss_weight&#39; 等键。</span>
<span class="sd">            validation_metrics (List[Dict]): 验证指标配置列表。每个字典应包含 &#39;metric&#39;, &#39;prediction&#39;, &#39;target&#39; 等键。</span>
<span class="sd">            lr (float, optional): 初始学习率。默认为 1e-3。</span>
<span class="sd">            lr_decay (float, optional): 学习率调度器中用于降低学习率的因子。默认为 0.1。</span>
<span class="sd">            lr_patience (int, optional): 学习率调度器在降低学习率前的等待轮数。默认为 100。</span>
<span class="sd">            lr_monitor (str, optional): 学习率调度器监控的指标。默认为 &quot;training/total_loss&quot;。</span>
<span class="sd">            epsilon (float, optional): AdamW 优化器的 epsilon 参数。默认为 1e-8。</span>
<span class="sd">            beta1 (float, optional): AdamW 优化器的 beta1 参数。默认为 0.99。</span>
<span class="sd">            beta2 (float, optional): AdamW 优化器的 beta2 参数。默认为 0.999。</span>
<span class="sd">            amsgrad (bool, optional): 是否在 AdamW 优化器中使用 AMSGrad 变体。默认为 True。</span>
<span class="sd">            max_points_to_scatter (int, optional): 在验证/测试结束时，用于生成散点图的最大数据点数。默认为 100000。</span>
<span class="sd">            post_processing (callable, optional): 一个可选的后处理模块，用于在测试时进行需要梯度的特殊计算。默认为 None。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">representation</span> <span class="o">=</span> <span class="n">representation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_module</span> <span class="o">=</span> <span class="n">output</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">validation_metrics</span>

        <span class="c1"># --- 优化器和学习率调度器参数 ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_decay</span> <span class="o">=</span> <span class="n">lr_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_patience</span> <span class="o">=</span> <span class="n">lr_patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_monitor</span> <span class="o">=</span> <span class="n">lr_monitor</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amsgrad</span> <span class="o">=</span> <span class="n">amsgrad</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span> <span class="o">=</span> <span class="n">max_points_to_scatter</span>
        <span class="c1"># post_processing 用于计算某些依赖于梯度反向传播的物理量</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span> <span class="o">=</span> <span class="n">post_processing</span>

        <span class="c1"># self.save_hyperparameters() # 保存超参数，便于从 checkpoint 加载</span>

        <span class="c1"># 检查输出模块是否需要计算关于位置的导数（例如，计算力）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requires_dr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_module</span><span class="o">.</span><span class="n">derivative</span>

<div class="viewcode-block" id="Model.calculate_loss">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.calculate_loss">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;根据 `self.losses` 配置计算总损失。</span>

<span class="sd">        例如，对于一个均方误差 (MSE) 损失，其计算方式为：</span>

<span class="sd">        .. math::</span>

<span class="sd">           L_{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2</span>

<span class="sd">        其中 :math:`y_i` 是真实值，:math:`\hat{y}_i` 是预测值。</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (dict): 当前批次的数据，包含目标值。</span>
<span class="sd">            result (dict): 模型的预测输出。</span>
<span class="sd">            mode (str): 当前阶段的名称（&#39;training&#39;, &#39;validation&#39;, or &#39;test&#39;），用于日志记录。</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: 计算得到的加权总损失。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># 遍历所有定义的损失函数</span>
        <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;metric&quot;</span><span class="p">]</span>

            <span class="c1"># 如果损失函数需要目标值</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span>
                <span class="n">loss_i</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="c1"># 如果损失函数只依赖于预测值（例如，正则化项）</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_i</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]])</span>
            
            <span class="c1"># 将当前损失乘以其权重并累加到总损失中</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;loss_weight&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_i</span>

            <span class="c1"># 获取损失函数的名称用于日志记录</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">):</span>
                <span class="n">lossname</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lossname</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># 记录单个损失项</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="n">mode</span>
                <span class="o">+</span> <span class="s2">&quot;/&quot;</span>
                <span class="o">+</span> <span class="n">lossname</span>
                <span class="o">+</span> <span class="s2">&quot;_&quot;</span>
                <span class="o">+</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">],</span>
                <span class="n">loss_i</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="Model.training_step">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.training_step">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        执行单个训练步骤。</span>

<span class="sd">        Args:</span>
<span class="sd">            data (dict): 当前批次的训练数据。</span>
<span class="sd">            batch_idx (int): 当前批次的索引。</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: 该批次的总训练损失。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_grads</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># 如果需要，为位置启用梯度</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># 前向传播</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;training&#39;</span><span class="p">)</span> <span class="c1"># 计算损失</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training/total_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 记录总损失</span>
        <span class="c1"># self.check_param() # 用于调试的辅助函数</span>
        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="Model.validation_step">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.validation_step">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        执行单个验证步骤。</span>

<span class="sd">        Args:</span>
<span class="sd">            data (dict): 当前批次的验证数据。</span>
<span class="sd">            batch_idx (int): 当前批次的索引。</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: 包含该批次预测值和目标值的字典，用于 `validation_epoch_end`。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># 在验证时，如果需要计算导数，需手动开启梯度计算</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">requires_dr</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_grads</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_loss</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;validation/total_loss&quot;</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span>
                 <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">)</span>
        
        <span class="c1"># 收集预测和目标值，用于 epoch 结束时进行可视化</span>
        <span class="n">outputs_pred</span><span class="p">,</span> <span class="n">outputs_target</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="n">outputs_pred</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  
            <span class="n">outputs_target</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>      
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">outputs_pred</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">outputs_target</span><span class="p">}</span></div>


<div class="viewcode-block" id="Model.validation_epoch_end">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.validation_epoch_end">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation_step_outputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        在验证的每个 epoch 结束时调用。</span>

<span class="sd">        该方法聚合所有验证批次的预测和目标，并生成散点图以可视化模型性能。</span>

<span class="sd">        Args:</span>
<span class="sd">            validation_step_outputs (List[dict]): 从 `validation_step` 返回的输出列表。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="c1"># 聚合来自所有验证批次的结果</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">][</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span>
                                 <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">validation_step_outputs</span><span class="p">])</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">][</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span>
                                    <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">validation_step_outputs</span><span class="p">])</span>
                
                <span class="c1"># 特殊处理复数类型数据，以便绘图</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">complex64</span><span class="p">):</span>
                    <span class="n">lossname</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">])</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">lossname</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;abs_mae&#39;</span><span class="p">:</span> <span class="c1"># 如果是绝对值误差，则取模</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
                        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># 否则，将实部和虚部拼接成一个向量</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pred</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">target</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># 控制要绘制的散点图的点数</span>
                <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">:</span>
                    <span class="n">random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
                    <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">)))</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">perm</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">]]</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">perm</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">]]</span>
                
                <span class="c1"># 生成并记录散点图</span>
                <span class="n">figure</span> <span class="o">=</span> <span class="n">scatter_plot</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">figname</span> <span class="o">=</span> <span class="s1">&#39;PredVSTarget_&#39;</span> <span class="o">+</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_figure</span><span class="p">(</span>
                    <span class="s1">&#39;validation/&#39;</span><span class="o">+</span><span class="n">figname</span><span class="p">,</span> <span class="n">figure</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_step</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span></div>


<div class="viewcode-block" id="Model.test_step">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.test_step">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        执行单个测试步骤。</span>

<span class="sd">        Args:</span>
<span class="sd">            data (dict): 当前批次的测试数据。</span>
<span class="sd">            batch_idx (int): 当前批次的索引。</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: 包含预测、目标和任何后处理值的字典。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">requires_dr</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_grads</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
        <span class="c1"># 如果定义了后处理步骤，则执行它</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;epc_output&#39;</span><span class="p">:</span>
                <span class="n">proessed_values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epc_mat&#39;</span><span class="p">:</span> <span class="n">pred</span><span class="p">[</span><span class="s1">&#39;epc_mat&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">proessed_values</span> <span class="o">=</span> <span class="kc">None</span>
            
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test/total_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_metrics</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span> 
        
        <span class="c1"># 收集预测和目标值</span>
        <span class="n">outputs_pred</span><span class="p">,</span> <span class="n">outputs_target</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="n">outputs_pred</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  
            <span class="n">outputs_target</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>      
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">outputs_pred</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">outputs_target</span><span class="p">,</span> <span class="s1">&#39;processed_values&#39;</span><span class="p">:</span> <span class="n">proessed_values</span><span class="p">}</span></div>


<div class="viewcode-block" id="Model.test_epoch_end">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.test_epoch_end">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_step_outputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        在测试的每个 epoch 结束时调用。</span>

<span class="sd">        该方法聚合所有测试批次的结果，将预测和目标保存到 .npy 文件，并生成最终的散点图。</span>

<span class="sd">        Args:</span>
<span class="sd">            test_step_outputs (List[dict]): 从 `test_step` 返回的输出列表。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="c1"># 聚合所有测试批次的结果</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">][</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span>
                                 <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">test_step_outputs</span><span class="p">])</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">][</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span>
                                    <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">test_step_outputs</span><span class="p">])</span>
                
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="p">):</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span>
                    
                <span class="c1"># 将预测和目标数组保存到文件</span>
                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;prediction_&#39;</span><span class="o">+</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;.npy&#39;</span><span class="p">),</span> <span class="n">pred</span><span class="p">)</span>
                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span>
                        <span class="s1">&#39;target_&#39;</span><span class="o">+</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;.npy&#39;</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
                
                <span class="c1"># --- 绘图逻辑 (与 validation_epoch_end 类似) ---</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">complex64</span><span class="p">):</span>
                    <span class="n">lossname</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">])</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">lossname</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;abs_mae&#39;</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
                        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pred</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">target</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># 控制要绘制的散点图的点数</span>
                <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">:</span>
                    <span class="n">random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
                    <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">)))</span>
                    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">perm</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">]]</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">perm</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_points_to_scatter</span><span class="p">]]</span>
                    
                <span class="n">figure</span> <span class="o">=</span> <span class="n">scatter_plot</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">figname</span> <span class="o">=</span> <span class="s1">&#39;PredVSTarget_&#39;</span> <span class="o">+</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_figure</span><span class="p">(</span>
                    <span class="s1">&#39;test/&#39;</span><span class="o">+</span><span class="n">figname</span><span class="p">,</span> <span class="n">figure</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_step</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span>
        
        <span class="c1"># 如果有后处理结果，也将其保存</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">post_processing</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;epc_output&#39;</span><span class="p">:</span>
                <span class="n">processed_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;processed_values&#39;</span><span class="p">][</span><span class="s2">&quot;epc_mat&quot;</span><span class="p">]</span>
                                        <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">test_step_outputs</span><span class="p">])</span>
                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;processed_values_&#39;</span><span class="o">+</span><span class="s1">&#39;epc_mat&#39;</span><span class="o">+</span><span class="s1">&#39;.npy&#39;</span><span class="p">),</span> <span class="n">processed_values</span><span class="p">)</span></div>

            
<div class="viewcode-block" id="Model.forward">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        定义模型的前向传播逻辑。</span>

<span class="sd">        Args:</span>
<span class="sd">            data (dict): 输入的批次数据。</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: 包含预测值的字典。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># torch.set_grad_enabled(True)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_grads</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">representation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_module</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">representation</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred</span></div>


<div class="viewcode-block" id="Model.log_metrics">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.log_metrics">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        根据 `self.metrics` 配置计算并记录所有评估指标。</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (dict): 当前批次的数据，包含目标值。</span>
<span class="sd">            result (dict): 模型的预测输出。</span>
<span class="sd">            mode (str): 当前阶段的名称（&#39;validation&#39; or &#39;test&#39;）。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">metric_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">metric_dict</span><span class="p">[</span><span class="s2">&quot;metric&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">metric_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="n">metric_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">metric_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span>
                <span class="n">loss_i</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span>
                    <span class="n">pred</span><span class="p">,</span> <span class="n">target</span>
                <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss_i</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span>
                    <span class="n">result</span><span class="p">[</span><span class="n">metric_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">]])</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">):</span>
                <span class="n">lossname</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lossname</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="n">mode</span>
                <span class="o">+</span> <span class="s2">&quot;/&quot;</span>
                <span class="o">+</span> <span class="n">lossname</span>
                <span class="o">+</span> <span class="s2">&quot;_&quot;</span>
                <span class="o">+</span> <span class="n">metric_dict</span><span class="p">[</span><span class="s2">&quot;prediction&quot;</span><span class="p">],</span>
                <span class="n">loss_i</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="Model.configure_optimizers">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.configure_optimizers">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        配置模型的优化器和学习率调度器。</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: 包含优化器列表和调度器配置列表的元组。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">opt</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_decay</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_patience</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
                <span class="n">cooldown</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_patience</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_monitor</span><span class="p">,</span>
            <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
            <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_enable_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        一个辅助函数，用于在需要计算导数时，为原子位置启用梯度计算。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">requires_dr</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">pos</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

<div class="viewcode-block" id="Model.check_param">
<a class="viewcode-back" href="../../../source/model_structure.html#HamGNN_v_2_0.models.Model.Model.check_param">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">check_param</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        一个调试辅助函数，用于打印模型参数的名称和梯度信息。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parms</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&gt;name:&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="s1">&#39;--&gt;grad_requirs:&#39;</span><span class="p">,</span> <span class="n">parms</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
                  <span class="s1">&#39;--&gt;grad_value:&#39;</span><span class="p">,</span> <span class="n">parms</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2025, HamGNN Team。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>