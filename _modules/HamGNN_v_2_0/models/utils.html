

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HamGNN_v_2_0.models.utils &mdash; HamGNN 2.0 文档</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=8ba3eb92"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/translations.js?v=beaddf03"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            HamGNN
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">API 文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../source/main_entry.html">主程序入口</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/model_structure.html">模型顶层结构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/gnn_core.html">GNN 核心层</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/model_components.html">模型通用组件</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/data_processing.html">数据处理与输入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../source/utilities.html">通用工具函数</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">HamGNN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">模块代码</a></li>
      <li class="breadcrumb-item active">HamGNN_v_2_0.models.utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>HamGNN_v_2_0.models.utils 源代码</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">/*</span>
<span class="sd"> * @Author: Yang Zhong </span>
<span class="sd"> * @Date: 2021-11-29 22:13:49 </span>
<span class="sd"> * @Last Modified by: Yang Zhong</span>
<span class="sd"> * @Last Modified time: 2021-11-29 22:26:42</span>
<span class="sd"> */</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">&quot;&quot;&quot;该模块提供了一系列在模型构建和训练过程中使用的工具函数和辅助类。</span>

<span class="sd">内容包括：</span>
<span class="sd">- 自定义激活函数 (SSP, SWISH) 和激活函数获取器。</span>
<span class="sd">- 各种损失函数 (cosine_similarity_loss, sum_zero_loss, Euclidean_loss, RMSELoss)。</span>
<span class="sd">- 绘图工具 (scatter_plot)。</span>
<span class="sd">- 配置解析和度量函数解析工具。</span>
<span class="sd">- 图算法辅助函数 (triplets)。</span>
<span class="sd">- 基于 e3nn 的张量操作类 (Expansion)。</span>
<span class="sd">- 其他张量操作工具函数。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_sparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparseTensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">Linear</span><span class="p">,</span> <span class="n">Bilinear</span><span class="p">,</span> <span class="n">Sigmoid</span><span class="p">,</span> <span class="n">Softplus</span><span class="p">,</span> <span class="n">ELU</span><span class="p">,</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">SELU</span><span class="p">,</span> <span class="n">SiLU</span><span class="p">,</span>
                      <span class="n">CELU</span><span class="p">,</span> <span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Tanh</span><span class="p">,</span> <span class="n">BatchNorm1d</span> <span class="k">as</span> <span class="n">BN</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">easydict</span><span class="w"> </span><span class="kn">import</span> <span class="n">EasyDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">gaussian_kde</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">e3nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">o3</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">global_add_pool</span><span class="p">,</span> <span class="n">global_max_pool</span><span class="p">,</span> <span class="n">global_mean_pool</span>

<div class="viewcode-block" id="swish">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.swish">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">swish</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Swish 激活函数。</span>

<span class="sd">    计算公式为 `x * sigmoid(x)`。</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): 输入张量。</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: 经过 Swish 激活后的张量。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span></div>


<div class="viewcode-block" id="linear_bn_act">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.linear_bn_act">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_bn_act</span><span class="p">(</span><span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">lbias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">use_batch_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;根据输入参数灵活构建一个线性层、批量归一化和激活函数的组合模块。</span>

<span class="sd">    该函数根据 `use_batch_norm` 和 `activation` 是否提供，来构造不同组合的模块。</span>

<span class="sd">    .. warning::</span>
<span class="sd">       该函数的返回值类型不是固定的。当 `use_batch_norm` 为 `False` 且 `activation`</span>
<span class="sd">       为 `None` 时，它返回一个独立的 `nn.Linear` 模块；在其他所有情况下，</span>
<span class="sd">       它返回一个 `nn.Sequential` 容器。调用者需要注意处理这个差异。</span>

<span class="sd">    Args:</span>
<span class="sd">        in_features (int): 线性层的输入特征维度。</span>
<span class="sd">        out_features (int): 线性层的输出特征维度。</span>
<span class="sd">        lbias (bool, optional): 线性层是否使用偏置。默认为 `False`。</span>
<span class="sd">        activation (Optional[Callable], optional): 要应用的激活函数实例。如果为 `None`，则不添加激活函数。默认为 `None`。</span>
<span class="sd">        use_batch_norm (bool, optional): 是否在激活之前应用批量归一化。默认为 `False`。</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[nn.Module, nn.Sequential]: 组建好的 Pytorch 模块。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">use_batch_norm</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">lbias</span><span class="p">),</span> <span class="n">BN</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">lbias</span><span class="p">),</span> <span class="n">BN</span><span class="p">(</span><span class="n">out_features</span><span class="p">),</span> <span class="n">activation</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">lbias</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">lbias</span><span class="p">),</span> <span class="n">activation</span><span class="p">)</span></div>


<div class="viewcode-block" id="SSP">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.SSP">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SSP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;应用逐元素的 Shifted SoftPlus (SSP) 激活函数。</span>

<span class="sd">    SSP 的计算公式为: :math:`\text{SSP}(x)=\text{Softplus}(x)-\text{Softplus}(0)`。</span>
<span class="sd">    这确保了 :math:`\text{SSP}(0)=0`。</span>

<span class="sd">    Args:</span>
<span class="sd">        beta: Softplus 公式中的 :math:`\beta` 值。默认为 1。</span>
<span class="sd">        threshold: 当输入值高于此阈值时，Softplus 将退化为线性函数。默认为 20。</span>

<span class="sd">    Shape:</span>
<span class="sd">        - 输入: :math:`(N, *)`，其中 `*` 表示任意数量的附加维度。</span>
<span class="sd">        - 输出: :math:`(N, *)`，形状与输入相同。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SSP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="c1"># 预计算 softplus(0) 的值以提高效率</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sp0</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<div class="viewcode-block" id="SSP.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.SSP.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp0</span></div>


<div class="viewcode-block" id="SSP.extra_repr">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.SSP.extra_repr">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;返回模块的额外表示信息，用于打印。&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s1">&#39;beta=</span><span class="si">{}</span><span class="s1">, threshold=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="SWISH">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.SWISH">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SWISH</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Swish 激活函数的模块封装。&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SWISH</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="SWISH.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.SWISH.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">swish</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="get_activation">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.get_activation">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_activation</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;根据名称字符串获取并实例化一个激活函数模块。</span>

<span class="sd">    支持的激活函数包括 &#39;softplus&#39;, &#39;ssp&#39;, &#39;elu&#39;, &#39;relu&#39;, &#39;selu&#39;, &#39;swish&#39;,</span>
<span class="sd">    &#39;tanh&#39;, &#39;silu&#39;, &#39;celu&#39;。对于 &#39;elu&#39; 和 &#39;celu&#39;，可以指定 alpha 参数，</span>
<span class="sd">    例如 &quot;elu(0.5)&quot;。</span>

<span class="sd">    Args:</span>
<span class="sd">        name (str): 激活函数的名称。</span>

<span class="sd">    Returns:</span>
<span class="sd">        nn.Module: 对应的激活函数实例。</span>

<span class="sd">    Raises:</span>
<span class="sd">        NameError: 如果请求的激活函数不受支持。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">act_name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c1"># 使用正则表达式解析可能带参数的激活函数名称，例如 &quot;elu(0.5)&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(\w+)\((\d+\.\d+)\)&quot;</span><span class="p">,</span> <span class="n">act_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">act_name</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">act_name</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># 默认 alpha 值</span>
        
    <span class="k">if</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;softplus&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Softplus</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;ssp&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SSP</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;elu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ELU</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ReLU</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;selu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SELU</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;swish&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SWISH</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">Tanh</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;silu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SiLU</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">act_name</span> <span class="o">==</span> <span class="s1">&#39;celu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">CELU</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NameError</span><span class="p">(</span><span class="s2">&quot;不支持的激活函数: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span></div>


<div class="viewcode-block" id="scatter_plot">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.scatter_plot">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">scatter_plot</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;生成一个预测值 vs. 目标值的散点图。</span>

<span class="sd">    图中会画出 y=x 的虚线作为参考。可选地，可以使用核密度估计</span>
<span class="sd">    为散点着色，但当前版本为简化实现，使用了固定的绿色。</span>

<span class="sd">    Args:</span>
<span class="sd">        pred (np.ndarray): 预测值的一维数组。</span>
<span class="sd">        target (np.ndarray): 目标值的一维数组。</span>

<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: 生成的 matplotlib Figure 对象。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        try:</span>
<span class="sd">        # Calculate the point density</span>
<span class="sd">        xy = np.vstack([pred, target])</span>
<span class="sd">        z = gaussian_kde(xy)(xy)</span>
<span class="sd">        idx = z.argsort()</span>
<span class="sd">        pred, target, z = pred[idx], target[idx], z[idx]</span>
<span class="sd">        # scatter plot</span>
<span class="sd">        ax.scatter(x=pred, y=target, s=25, c=z, marker=&quot;.&quot;)</span>
<span class="sd">    except:</span>
<span class="sd">        ax.scatter(x=pred, y=target, s=25, c=&#39;g&#39;, alpha=0.5, marker=&quot;.&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 简单的散点图实现</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Prediction VS Target&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span> <span class="c1"># 保证 x,y 轴刻度相同</span>
    
    <span class="c1"># 绘制 y=x 参考线</span>
    <span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">],</span> <span class="p">[</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">],</span>
            <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
            
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Target&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span></div>


<div class="viewcode-block" id="cosine_similarity_loss">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.cosine_similarity_loss">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">cosine_similarity_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算两个向量之间的余弦相似度损失。</span>

<span class="sd">    损失定义为 `1 - cos(theta)`，其中 `theta` 是两个向量的夹角。</span>
<span class="sd">    该损失鼓励两个向量指向相同的方向。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">cosine_similarity_loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="cosine_similarity_loss.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.cosine_similarity_loss.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。&quot;&quot;&quot;</span>
        <span class="c1"># 逐元素点积</span>
        <span class="n">vec_product</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span><span class="o">*</span><span class="n">target</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 计算各自的 L2 范数</span>
        <span class="n">pred_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># 计算损失，并取批次平均</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">-</span> <span class="n">vec_product</span><span class="o">/</span><span class="p">(</span><span class="n">pred_norm</span><span class="o">*</span><span class="n">target_norm</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div>
</div>


<div class="viewcode-block" id="sum_zero_loss">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.sum_zero_loss">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">sum_zero_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;一个约束预测向量总和为零的损失。</span>

<span class="sd">    该损失计算预测向量在批次维度上求和后的 L2 范数。</span>
<span class="sd">    这在需要满足某些物理守恒定律（如总力为零）时非常有用。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">sum_zero_loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="sum_zero_loss.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.sum_zero_loss.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。 target 在此损失中未使用。&quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span></div>
</div>


<div class="viewcode-block" id="Euclidean_loss">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.Euclidean_loss">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Euclidean_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算预测值和目标值之间的平均欧几里得距离。&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Euclidean_loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="Euclidean_loss.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.Euclidean_loss.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。&quot;&quot;&quot;</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div>
</div>


<div class="viewcode-block" id="RMSELoss">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.RMSELoss">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RMSELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算均方根误差 (RMSE) 损失。&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RMSELoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<div class="viewcode-block" id="RMSELoss.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.RMSELoss.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">))</span></div>
</div>


<div class="viewcode-block" id="parse_metric_func">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.parse_metric_func">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">parse_metric_func</span><span class="p">(</span><span class="n">losses_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;解析一个包含损失函数信息的列表，并将字符串名称替换为实际的损失函数实例。</span>

<span class="sd">    Args:</span>
<span class="sd">        losses_list (list): 一个字典列表，每个字典包含 &#39;metric&#39; (str) 和其他参数。</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: 更新后的列表，其中 &#39;metric&#39; 的值被替换为 nn.Module 实例。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">loss_dict</span> <span class="ow">in</span> <span class="n">losses_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;mse&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;mae&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cosine_similarity&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_similarity_loss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;sum_zero&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_zero_loss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;euclidean_loss&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Euclidean_loss</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;rmse&#39;</span><span class="p">:</span>
            <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">RMSELoss</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;不支持的度量函数: </span><span class="si">{</span><span class="n">loss_dict</span><span class="p">[</span><span class="s2">&quot;metric&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">losses_list</span></div>


<div class="viewcode-block" id="get_hparam_dict">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.get_hparam_dict">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_hparam_dict</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">EasyDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;从配置对象中提取并格式化用于日志记录的超参数字典。</span>

<span class="sd">    它根据 `config.setup.GNN_Net` 的值从 `config.representation_nets`</span>
<span class="sd">    中选择对应的参数字典，并进行一些格式化处理。</span>

<span class="sd">    Args:</span>
<span class="sd">        config (EasyDict): 全局配置对象。</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: 格式化后的超参数字典，适用于 TensorBoard 等日志工具。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 查找与GNN网络名称匹配的参数配置</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;dimnet&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">dimnet_params</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;edge_gnn&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">Edge_GNN</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;schnet&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">SchNet</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cgcnn&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">cgcnn</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cgcnn_edge&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">cgcnn_edge</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;painn&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">painn</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cgcnn_triplet&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">cgcnn_triplet</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;dimenet_triplet&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">dimenet_triplet</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;dimeham&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">dimeham</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;dimeorb&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">dimeorb</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;schnorb&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">schnorb</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;nequip&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">nequip</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;hamgnn_pre&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">HamGNN_pre</span>
    <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="o">.</span><span class="n">lower</span><span class="p">()[:</span><span class="mi">6</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;hamgnn&#39;</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">representation_nets</span><span class="o">.</span><span class="n">HamGNN_pre</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;不支持的网络 </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">quit</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">hparam_dict</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="n">hparam_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;GNN_Name&#39;</span><span class="p">:</span> <span class="n">config</span><span class="o">.</span><span class="n">setup</span><span class="o">.</span><span class="n">GNN_Net</span><span class="p">}</span>
    <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="triplets">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.triplets">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">triplets</span><span class="p">(</span><span class="n">edge_index</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cell_shift</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;从边列表计算原子三元组 (k -&gt; j -&gt; i)。</span>

<span class="sd">    这个函数对于构建需要三体相互作用（如键角）的图模型至关重要。</span>
<span class="sd">    它首先将边列表转换为稀疏邻接矩阵，然后通过邻接矩阵的乘积思想</span>
<span class="sd">    有效地找到所有通过一个中间节点 `j` 连接的原子对 `(k, i)`。</span>

<span class="sd">    Args:</span>
<span class="sd">        edge_index (torch.Tensor): 形状为 `(2, N_edges)` 的边索引张量，表示 `j -&gt; i` 的边。</span>
<span class="sd">        num_nodes (int): 图中的节点总数。</span>
<span class="sd">        cell_shift (torch.Tensor): 形状为 `(N_edges, 3)` 的张量，表示每条边跨越的晶胞偏移。</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: 包含三元组信息的元组:</span>
<span class="sd">            - col, row (torch.Tensor): 原始的边索引。</span>
<span class="sd">            - idx_i, idx_j, idx_k (torch.Tensor): 三元组中 `i`, `j`, `k` 的原子索引。</span>
<span class="sd">            - idx_kj, idx_ji (torch.Tensor): 构成三元组的两条边 `k-&gt;j` 和 `j-&gt;i` 的原始边索引。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>  <span class="c1"># j-&gt;i</span>
            
    <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">row</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 构建稀疏邻接矩阵，其中值为边的索引</span>
    <span class="n">adj_t</span> <span class="o">=</span> <span class="n">SparseTensor</span><span class="p">(</span>
        <span class="n">row</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">row</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">sparse_sizes</span><span class="o">=</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># 对于每个 j-&gt;i 的边 (由 row 表示)，找到所有指向 j 的邻居 k</span>
    <span class="n">adj_t_row</span> <span class="o">=</span> <span class="n">adj_t</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
    <span class="n">num_triplets</span> <span class="o">=</span> <span class="n">adj_t_row</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
                    
    <span class="c1"># --- 构建三元组的节点索引 (k-&gt;j-&gt;i) ---</span>
    <span class="n">idx_i</span> <span class="o">=</span> <span class="n">col</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_triplets</span><span class="p">)</span>
    <span class="n">idx_j</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_triplets</span><span class="p">)</span>
    <span class="n">idx_k</span> <span class="o">=</span> <span class="n">adj_t_row</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">col</span><span class="p">()</span>
                   
    <span class="c1"># --- 构建三元组的边索引 (k-&gt;j, j-&gt;i) ---</span>
    <span class="n">idx_kj</span> <span class="o">=</span> <span class="n">adj_t_row</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">value</span><span class="p">()</span> <span class="c1"># 边 k-&gt;j 的索引</span>
    <span class="n">idx_ji</span> <span class="o">=</span> <span class="n">adj_t_row</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">row</span><span class="p">()</span> <span class="c1"># 边 j-&gt;i 的索引</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    idx_i -&gt; pos[idx_i]</span>
<span class="sd">    idx_j -&gt; pos[idx_j] - nbr_shift[idx_ji]</span>
<span class="sd">    idx_k -&gt; pos[idx_k] - nbr_shift[idx_ji] - nbr_shift[idx_kj]</span>
<span class="sd">    &quot;&quot;&quot;</span>           
    <span class="c1"># --- 过滤掉无效的三元组 ---</span>
    <span class="c1"># 一个原子不能通过两个周期性边界的像成为自己的邻居，形成 k=i 的情况</span>
    <span class="c1"># 除非这两个像的相对晶胞位移不为零</span>
    <span class="n">relative_cell_shift</span> <span class="o">=</span> <span class="n">cell_shift</span><span class="p">[</span><span class="n">idx_kj</span><span class="p">]</span> <span class="o">+</span> <span class="n">cell_shift</span><span class="p">[</span><span class="n">idx_ji</span><span class="p">]</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx_i</span> <span class="o">!=</span> <span class="n">idx_k</span><span class="p">)</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">relative_cell_shift</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">idx_i</span><span class="p">,</span> <span class="n">idx_j</span><span class="p">,</span> <span class="n">idx_k</span><span class="p">,</span> <span class="n">idx_kj</span><span class="p">,</span> <span class="n">idx_ji</span> <span class="o">=</span> <span class="n">idx_i</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">idx_j</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">idx_k</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">idx_kj</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">idx_ji</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
               
    <span class="k">return</span> <span class="n">col</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">idx_i</span><span class="p">,</span> <span class="n">idx_j</span><span class="p">,</span> <span class="n">idx_k</span><span class="p">,</span> <span class="n">idx_kj</span><span class="p">,</span> <span class="n">idx_ji</span></div>


<div class="viewcode-block" id="prod">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.prod">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">prod</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;计算序列中所有元素的乘积。&quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">*=</span> <span class="n">a</span>
    <span class="k">return</span> <span class="n">out</span></div>


<div class="viewcode-block" id="Expansion">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.Expansion">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Expansion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;一个使用 e3nn 库实现的等变特征扩展模块。</span>

<span class="sd">    该模块的核心功能是将一个输入特征（表示为一个 `e3nn` 的不可约表示 `irrep_in`），</span>
<span class="sd">    通过张量积分解，映射到一个由两个其他不可约表示 (`irrep_out_1` 和 `irrep_out_2`)</span>
<span class="sd">    构成的二维特征空间中。这在构建等变神经网络的交互块时非常关键，因为它允许</span>
<span class="sd">    信息在不同阶数的张量特征之间进行混合和传递。</span>

<span class="sd">    例如，一个向量特征 (`1o`) 与另一个向量特征 (`1o`) 交互，可以产生标量 (`0e`)、</span>
<span class="sd">    反对称矩阵/伪向量 (`1o`) 和对称无迹矩阵 (`2e`) 特征。这个模块就是实现这种</span>
<span class="sd">    分解和映射的计算单元。</span>

<span class="sd">    计算的核心是利用 Wigner 3-j 符号 (`o3.wigner_3j`)，它描述了三个角动量</span>
<span class="sd">    如何耦合。</span>

<span class="sd">    Attributes:</span>
<span class="sd">        irrep_in (o3.Irreps): 输入特征的不可约表示。</span>
<span class="sd">        irrep_out_1 (o3.Irreps): 输出特征的第一个维度（行）的不可约表示。</span>
<span class="sd">        irrep_out_2 (o3.Irreps): 输出特征的第二个维度（列）的不可约表示。</span>
<span class="sd">        internal_weights (bool): 控制权重生成方式。如果为 `True`，权重是模块内部</span>
<span class="sd">            固定的 `nn.Parameter`；如果为 `False`，权重由一个 `o3.Linear` 层从</span>
<span class="sd">            输入特征动态生成。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">irrep_in</span><span class="p">,</span> <span class="n">irrep_out_1</span><span class="p">,</span> <span class="n">irrep_out_2</span><span class="p">,</span> <span class="n">internal_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;构造 Expansion 类的实例。</span>

<span class="sd">        Args:</span>
<span class="sd">            irrep_in (o3.Irreps): 输入特征的 e3nn 不可约表示。</span>
<span class="sd">            irrep_out_1 (o3.Irreps): 输出特征的第一维（行）的 e3nn 不可约表示。</span>
<span class="sd">            irrep_out_2 (o3.Irreps): 输出特征的第二维（列）的 e3nn 不可约表示。</span>
<span class="sd">            internal_weights (bool, optional): 是否使用内部权重。默认为 `False`。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span> <span class="o">=</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">(</span><span class="n">irrep_in</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span> <span class="o">=</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">(</span><span class="n">irrep_out_1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_2</span> <span class="o">=</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">(</span><span class="n">irrep_out_2</span><span class="p">)</span>
        
        <span class="c1"># --- 步骤 1: 查找所有可能的分解路径 ---</span>
        <span class="c1"># 根据群论规则 (ir_in 必须存在于 ir_out1 和 ir_out2 的张量积中)，</span>
        <span class="c1"># 确定所有合法的从 `irrep_in`到 `(irrep_out_1, irrep_out_2)` 对的映射路径。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instructions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_expansion_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_2</span><span class="p">)</span>
        
        <span class="c1"># --- 步骤 2: 计算所需权重的数量 ---</span>
        <span class="c1"># 路径权重：每个合法的分解路径都需要一组可学习的权重。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_path_weight</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">ins</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">instructions</span> <span class="k">if</span> <span class="n">ins</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
        <span class="c1"># 偏置权重：仅当输入是标量 (l=0) 时，才存在偏置项。</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bias</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span> <span class="k">for</span> <span class="n">ins</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">instructions</span> <span class="k">if</span> <span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_path_weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bias</span>

        <span class="c1"># --- 步骤 3: 初始化权重 ---</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">internal_weights</span> <span class="o">=</span> <span class="n">internal_weights</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_weights</span><span class="p">:</span>
            <span class="c1"># 将所有权重（路径权重+偏置）创建为模块内部的一个可训练参数。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_path_weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bias</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 创建一个 e3nn 线性层，用于从输入特征动态地预测所有权重。</span>
            <span class="c1"># 输出是一个标量类型(0e)，通道数为 num_weights。</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_weight_bias</span> <span class="o">=</span> <span class="n">o3</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">,</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">([(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_weights</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))]))</span>

<div class="viewcode-block" id="Expansion.forward">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.Expansion.forward">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;定义前向传播逻辑。</span>

<span class="sd">        Args:</span>
<span class="sd">            x_in (torch.Tensor): 输入特征张量，其维度应与 `irrep_in` 匹配。</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: 输出的二维特征张量，其形状为 `(N_batch, irrep_out_1.dim, irrep_out_2.dim)`。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_weights</span><span class="p">:</span>
            <span class="c1"># 如果使用内部权重，则直接使用 `self.weights`，不依赖输入。</span>
            <span class="n">weights</span><span class="p">,</span> <span class="n">bias_weights</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span> <span class="c1"># Placeholder，实际在循环中使用 self.weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># 如果使用动态权重，则通过线性层从输入 `x_in` 生成权重。</span>
            <span class="n">weight_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_weight_bias</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
            <span class="n">weights</span><span class="p">,</span> <span class="n">bias_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">weight_bias</span><span class="p">,</span> 
                                               <span class="n">split_size_or_sections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_path_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bias</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">batch_num</span> <span class="o">=</span> <span class="n">x_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 将输入的扁平化张量根据 irrep_in 的定义，切分成不同不可约表示对应的块。</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_in_s</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_in</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">dim</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_in_s</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">x_in</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">mul_ir</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">mul_ir</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mul_ir</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="o">.</span><span class="n">slices</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">)]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">flat_weight_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">bias_weight_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># --- 核心计算：遍历所有合法的分解路径 ---</span>
        <span class="k">for</span> <span class="n">ins</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">instructions</span><span class="p">:</span>
            <span class="n">mul_ir_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="p">[</span><span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">mul_ir_out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="p">[</span><span class="n">ins</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">mul_ir_out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_2</span><span class="p">[</span><span class="n">ins</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">x_in_s</span><span class="p">[</span><span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            
            <span class="c1"># 获取 Wigner 3-j 符号，这是进行等变张量积的核心。</span>
            <span class="n">w3j_matrix</span> <span class="o">=</span> <span class="n">o3</span><span class="o">.</span><span class="n">wigner_3j</span><span class="p">(</span>
                <span class="n">mul_ir_out1</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">l</span><span class="p">,</span> <span class="n">mul_ir_out2</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">l</span><span class="p">,</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">x_in</span><span class="p">)</span>
            
            <span class="c1"># 如果该路径需要权重 (ins[3] is True)</span>
            <span class="k">if</span> <span class="n">ins</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">or</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># 对应 internal_weights=True 的情况</span>
                    <span class="c1"># 从内部参数 self.weights 中切片出当前路径所需的权重</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">flat_weight_index</span><span class="p">:</span><span class="n">flat_weight_index</span> <span class="o">+</span> <span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="c1"># `einsum` 执行带权重的张量积</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;wuv, ijk, bwk-&gt; buivj&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">w3j_matrix</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span> <span class="o">/</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">mul</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># 对应 internal_weights=False 的情况</span>
                    <span class="c1"># 从动态生成的权重中切片</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:,</span> <span class="n">flat_weight_index</span><span class="p">:</span><span class="n">flat_weight_index</span> <span class="o">+</span> <span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="c1"># 先将权重与输入特征作用</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bwuv, bwk-&gt; buvk&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
                    <span class="c1"># 如果输入是标量 (l=0)，则添加偏置项</span>
                    <span class="k">if</span> <span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">bias_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">bias_weight</span> <span class="o">=</span> <span class="n">bias_weights</span><span class="p">[:,</span><span class="n">bias_weight_index</span><span class="p">:</span><span class="n">bias_weight_index</span> <span class="o">+</span> <span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:])]</span><span class="o">.</span>\
                            <span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
                        <span class="n">bias_weight_index</span> <span class="o">+=</span> <span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="n">bias_weight</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="c1"># 再与 3j 符号作用，完成张量积</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ijk, buvk-&gt;buivj&quot;</span><span class="p">,</span> <span class="n">w3j_matrix</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span> <span class="o">/</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">mul</span>
                <span class="n">flat_weight_index</span> <span class="o">+=</span> <span class="n">prod</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># 如果路径不需要权重，则权重视为全 1</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;uvw, ijk, bwk-&gt; buivj&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">type</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">w3j_matrix</span><span class="p">,</span>
                    <span class="n">x1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">mul_ir_in</span><span class="o">.</span><span class="n">ir</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="n">mul_ir_out1</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">mul_ir_out2</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="c1"># 将同一目标块 (key) 的结果累加起来</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">ins</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ins</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+</span> <span class="n">result</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        
        <span class="c1"># --- 步骤 4: 组装最终的输出张量 ---</span>
        <span class="c1"># 将所有计算出的块按照 (irrep_out_1, irrep_out_2) 的网格结构拼接起来。</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="p">)):</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_2</span><span class="p">)):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="c1"># 如果某个块没有合法的分解路径，则用零填充。</span>
                    <span class="n">blocks</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span>
                                           <span class="n">device</span><span class="o">=</span><span class="n">x_in</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">x_in</span><span class="o">.</span><span class="n">type</span><span class="p">())]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">blocks</span> <span class="o">+=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]]</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_num</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="Expansion.get_expansion_path">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.Expansion.get_expansion_path">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_expansion_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">irrep_in</span><span class="p">:</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">,</span> <span class="n">irrep_out_1</span><span class="p">:</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">,</span> <span class="n">irrep_out_2</span><span class="p">:</span> <span class="n">o3</span><span class="o">.</span><span class="n">Irreps</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;计算所有可能的从输入 irrep 到输出 irrep 对的分解路径。</span>

<span class="sd">        路径存在的条件是，根据群论的耦合规则，`ir_in` 必须包含在</span>
<span class="sd">        `ir_out1` 和 `ir_out2` 的张量积中。</span>

<span class="sd">        Args:</span>
<span class="sd">            irrep_in (o3.Irreps): 输入的不可约表示。</span>
<span class="sd">            irrep_out_1 (o3.Irreps): 输出的第一个不可约表示。</span>
<span class="sd">            irrep_out_2 (o3.Irreps): 输出的第二个不可约表示。</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: 一个包含指令的列表。每个指令是一个列表，格式为</span>
<span class="sd">                  `[输入irrep索引, 输出1 irrep索引, 输出2 irrep索引, 是否需要权重, 1.0, [multiplicities]]`。</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">instructions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span>  <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">num_in</span><span class="p">,</span> <span class="n">ir_in</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">irrep_in</span><span class="p">):</span>
            <span class="k">for</span>  <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">num_out1</span><span class="p">,</span> <span class="n">ir_out1</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">irrep_out_1</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">num_out2</span><span class="p">,</span> <span class="n">ir_out2</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">irrep_out_2</span><span class="p">):</span>
                    <span class="c1"># 这是核心的群论选择规则</span>
                    <span class="k">if</span> <span class="n">ir_in</span> <span class="ow">in</span> <span class="n">ir_out1</span> <span class="o">*</span> <span class="n">ir_out2</span><span class="p">:</span>
                        <span class="n">instructions</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="n">num_in</span><span class="p">,</span> <span class="n">num_out1</span><span class="p">,</span> <span class="n">num_out2</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">instructions</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_in</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="si">}</span><span class="s1">x</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">irrep_out_1</span><span class="si">}</span><span class="s1"> and bias </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_bias</span><span class="si">}</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;with parameters </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_path_weight</span><span class="si">}</span><span class="s1">&#39;</span></div>



<div class="viewcode-block" id="blockwise_2x2_concat">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.blockwise_2x2_concat">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">blockwise_2x2_concat</span><span class="p">(</span>
    <span class="n">top_left</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">top_right</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bottom_left</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bottom_right</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;将四个张量以 2x2 的块状模式拼接成一个双倍大小的张量。</span>

<span class="sd">    拼接模式如下:</span>
<span class="sd">    [top_left | top_right]</span>
<span class="sd">    ----------------------</span>
<span class="sd">    [bottom_left | bottom_right]</span>

<span class="sd">    Args:</span>
<span class="sd">        top_left (torch.Tensor): 形状为 `[N, H, W]` 的张量。</span>
<span class="sd">        top_right (torch.Tensor): 与 `top_left` 形状相同的张量。</span>
<span class="sd">        bottom_left (torch.Tensor): 与 `top_left` 形状相同的张量。</span>
<span class="sd">        bottom_right (torch.Tensor): 与 `top_left` 形状相同的张量。</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: 拼接后的张量，形状为 `[N, 2*H, 2*W]`。</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: 如果输入的张量形状不匹配。</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; a = torch.ones(2, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; b = torch.zeros(2, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; result = blockwise_2x2_concat(a, b, b, a)</span>
<span class="sd">        &gt;&gt;&gt; result.shape</span>
<span class="sd">        torch.Size([2, 6, 6])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 验证输入张量的维度</span>
    <span class="n">expected_shape</span> <span class="o">=</span> <span class="n">top_left</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">top_right</span><span class="p">,</span> <span class="n">bottom_left</span><span class="p">,</span> <span class="n">bottom_right</span><span class="p">],</span> <span class="n">start</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">expected_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;张量 </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> 的形状 </span><span class="si">{</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> 与第一个张量的形状 </span><span class="si">{</span><span class="n">expected_shape</span><span class="si">}</span><span class="s2"> 不匹配。&quot;</span>
            <span class="p">)</span>

    <span class="c1"># 首先进行水平拼接 (维度 W)</span>
    <span class="n">top_row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">top_left</span><span class="p">,</span> <span class="n">top_right</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bottom_row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">bottom_left</span><span class="p">,</span> <span class="n">bottom_right</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 然后进行垂直拼接 (维度 H)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">top_row</span><span class="p">,</span> <span class="n">bottom_row</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span></div>



<div class="viewcode-block" id="extract_elements_above_threshold">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.extract_elements_above_threshold">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">extract_elements_above_threshold</span><span class="p">(</span>
    <span class="n">condition_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">source_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;根据条件张量中的值是否超过阈值，从源张量中提取元素。</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        condition_tensor (torch.Tensor): 用于与阈值比较的张量，形状为 `[N_batch, N, N]`。</span>
<span class="sd">        source_tensor (torch.Tensor): 从中提取值的源张量，形状为 `[N_batch, N, N]`。</span>
<span class="sd">        threshold (float): `condition_tensor` 中元素的最小阈值，超过该值则触发提取。</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: 从 `source_tensor` 中提取的一维值张量。</span>
<span class="sd">        </span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: 如果输入张量的形状不匹配。</span>
<span class="sd">        </span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; S = torch.randn(2, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; H = torch.randn(2, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; result = extract_elements_above_threshold(S, H, 0.5)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 验证输入形状</span>
    <span class="k">if</span> <span class="n">condition_tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">source_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;形状不匹配: </span><span class="si">{</span><span class="n">condition_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> vs </span><span class="si">{</span><span class="n">source_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 创建布尔掩码</span>
    <span class="n">threshold_mask</span> <span class="o">=</span> <span class="n">condition_tensor</span> <span class="o">&gt;</span> <span class="n">threshold</span>
    
    <span class="c1"># 提取相应的元素</span>
    <span class="n">extracted_values</span> <span class="o">=</span> <span class="n">source_tensor</span><span class="p">[</span><span class="n">threshold_mask</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">extracted_values</span></div>


<div class="viewcode-block" id="upgrade_tensor_precision">
<a class="viewcode-back" href="../../../source/utilities.html#HamGNN_v_2_0.models.utils.upgrade_tensor_precision">[文档]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">upgrade_tensor_precision</span><span class="p">(</span><span class="n">tensor_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;升级给定字典中特定类型张量的精度。</span>
<span class="sd">    </span>
<span class="sd">    该函数遍历字典，将 `torch.float32` 张量转换为 `torch.float64` (double)，</span>
<span class="sd">    并将 `torch.complex64` 张量转换为 `torch.complex128`。</span>
<span class="sd">    所有其他类型的张量保持不变。转换过程中会保留张量的原始设备。</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        tensor_dict (dict): 包含 PyTorch 张量的字典。</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        None: 该函数直接在原地修改字典。</span>
<span class="sd">    Notes:</span>
<span class="sd">        对于 `float32` 类型的张量，可以使用 `.to(dtype=torch.float64)` 或 `.double()` 两种方法来将其转换为 `float64` 类型。为了与复数张量的转换方式保持一致，此函数中使用了 `.to()` 方法。</span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; data = {&#39;float_tensor&#39;: torch.tensor([1.0, 2.0], dtype=torch.float32)}</span>
<span class="sd">        &gt;&gt;&gt; upgrade_tensor_precision(data)</span>
<span class="sd">        &gt;&gt;&gt; print(data[&#39;float_tensor&#39;].dtype)</span>
<span class="sd">        torch.float64</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tensor_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">:</span>
                <span class="n">tensor_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2025, HamGNN Team。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>